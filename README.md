# DL_MiniProject1
A residual neural network (ResNet) is an artificial neural network (ANN) which utilizes skip connections, or shortcuts to jump over some layers.  Typical ResNet models are implemented with double- or triple- layer skips that contain nonlinearities and batch normalization in between. In this project, we propose a ResNet-18 architecture which uses SGD Nesterov optimizer in combination with Manifold-Mixup regularization and Affine Transform data augmentation techniques. We provide comprehensive empirical evidence showing that this residual network performs optimally for CIFAR-10 dataset with a test accuracy of 94.1%.
